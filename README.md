# cc22-23-storyteller

1. Prompt the user to upload a sequence of images to our Storyteller Model;
2. Storyteller Model generates captions for the prompted images;
3. Storyteller Model generates a story by using Text Completion.

# Execution

1. Set the environment variable `OPENAI_API_KEY` to the API key, which can be generated from [OpenAI](https://beta.openai.com/account/api-keys);
2. Set the python environment to Python3.8.9 with `pip install virtualenv` and `virtualenv -p python3.8 CC22-23-Storyteller`;
3. Activate the virtual environment with `source CC22-23-Storyteller/.venv/bin/activate`im Mac OS and Unix systems or 
   with `source CC22-23-Storyteller/.venv/Scripts/activate` in Windows systems;
4. Install the dependencies in `requirements.txt` file with `pip install -r requirements.txt`;
5. Navigate to `./src` folder;
6. Run with `python3 main.py`.

# Architecture

1. BLIP (Bi-directional Language and Image Pre-training) is used to generate captions for the prompted images.
2. GPT3 (Generative Pre-trained Transformer 3) is used to generate a story by using Text Completion based on the captions generated by BLIP and the user's choice of the story's genre and format.
